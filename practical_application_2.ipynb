{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### CRISP-DM Phase 1: Business Understanding\n",
       "\n",
       "The objective of this project is to help a used car dealership understand what factors most strongly influence a vehicle’s resale price.\n",
       "By developing predictive models, the dealership can estimate prices more accurately and identify high-value vehicles for acquisition and sale.\n",
       "The analysis supports better pricing, purchasing, and inventory management decisions, enabling data-driven operations.\n",
       "Ultimately, the insights will help the dealership focus on vehicles that maximize profitability and meet customer demand efficiently.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "phase_1_text_section_1 = \"\"\"\n",
    "### CRISP-DM Phase 1: Business Understanding\n",
    "\n",
    "The objective of this project is to help a used car dealership understand what factors most strongly influence a vehicle’s resale price.\n",
    "By developing predictive models, the dealership can estimate prices more accurately and identify high-value vehicles for acquisition and sale.\n",
    "The analysis supports better pricing, purchasing, and inventory management decisions, enabling data-driven operations.\n",
    "Ultimately, the insights will help the dealership focus on vehicles that maximize profitability and meet customer demand efficiently.\n",
    "\"\"\"\n",
    "display(Markdown(phase_1_text_section_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### CRISP-DM Phase 1: Data Problem Definition\n",
       "This business understanding/problem  can be translated into a supervised regression modeling problem. Using the provided dataset, which contains attributes such as year, manufacturer, model, condition, cylinders, fuel, odometer, title_status, transmission, drive, size, type, paint_color, state, and the target variable price, the goal is to build and evaluate predictive models that estimate vehicle price based on these input features.\n",
       "The analysis will involve data preprocessing (handling missing values, encoding categorical variables, scaling numeric features), feature engineering (e.g., polynomial transformations), and modeling using algorithms such as  Linear Regression, LASSO, Ridge, Logistic Regression, and ARMA.\n",
       "By analyzing the model coefficients and feature importance, we aim to identify the key predictors of car prices and quantify their effect, ultimately revealing which factors are most valued by consumers in the used car market.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "phase_1_text_section_1 = \"\"\"\n",
    "### CRISP-DM Phase 1: Data Problem Definition\n",
    "This business understanding/problem  can be translated into a supervised regression modeling problem. Using the provided dataset, which contains attributes such as year, manufacturer, model, condition, cylinders, fuel, odometer, title_status, transmission, drive, size, type, paint_color, state, and the target variable price, the goal is to build and evaluate predictive models that estimate vehicle price based on these input features.\n",
    "The analysis will involve data preprocessing (handling missing values, encoding categorical variables, scaling numeric features), feature engineering (e.g., polynomial transformations), and modeling using algorithms such as  Linear Regression, LASSO, Ridge, Logistic Regression, and ARMA.\n",
    "By analyzing the model coefficients and feature importance, we aim to identify the key predictors of car prices and quantify their effect, ultimately revealing which factors are most valued by consumers in the used car market.\n",
    "\"\"\"\n",
    "display(Markdown(phase_1_text_section_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Script started ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Goal\n",
       "--------\n",
       "To help a used car dealership understand what factors influence used car prices\n",
       "and predict price levels or identify high-value vehicles.\n",
       "\n",
       "### Business Objectives:\n",
       "------------------------\n",
       "1. Predict used car resale prices using regression models.\n",
       "2. Classify vehicles as \"high-value\" or \"low-value\" for better inventory targeting.\n",
       "3. Forecast future average price trends for business strategy and acquisition planning.\n",
       "4. Generate actionable insights to guide pricing, procurement, and marketing decisions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CRISP-DM FRAMEWORK IMPLEMENTATION\n",
    "# USED CAR PRICE MODELING — REGRESSION, CLASSIFICATION & FORECASTING\n",
    "# =============================================================================\n",
    "\n",
    "# PHASE 0: LIBRARY IMPORTS & INITIALIZATION\n",
    "# -----------------------------------------------------------------------------\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error,\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Create folder for saving images\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Start total timer\n",
    "global_start = time.time()\n",
    "print(\"\\n=== Script started ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 1: BUSINESS UNDERSTANDING\n",
    "# -----------------------------------------------------------------------------\n",
    "business_understanding = \"\"\"\n",
    "### Goal\n",
    "--------\n",
    "To help a used car dealership understand what factors influence used car prices\n",
    "and predict price levels or identify high-value vehicles.\n",
    "\n",
    "### Business Objectives:\n",
    "------------------------\n",
    "1. Predict used car resale prices using regression models.\n",
    "2. Classify vehicles as \"high-value\" or \"low-value\" for better inventory targeting.\n",
    "3. Forecast future average price trends for business strategy and acquisition planning.\n",
    "4. Generate actionable insights to guide pricing, procurement, and marketing decisions.\n",
    "\"\"\"\n",
    "display(Markdown(business_understanding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (426880, 18)\n",
      "\n",
      "Sample columns: ['id', 'region', 'price', 'year', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'odometer']\n",
      "size            0.717675\n",
      "cylinders       0.416225\n",
      "condition       0.407852\n",
      "VIN             0.377254\n",
      "drive           0.305863\n",
      "paint_color     0.305011\n",
      "type            0.217527\n",
      "manufacturer    0.041337\n",
      "title_status    0.019308\n",
      "model           0.012362\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 2: DATA UNDERSTANDING\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(\"data/vehicles.csv\")\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "\n",
    "# Inspect structure and missingness\n",
    "print(\"\\nSample columns:\", df.columns.tolist()[:10])\n",
    "print(df.isna().mean().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after cleaning: (379846, 16)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 3: DATA PREPARATION\n",
    "# -----------------------------------------------------------------------------\n",
    "# Drop irrelevant columns\n",
    "df.drop(columns=[\"id\", \"VIN\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Fill missing categorical values\n",
    "for col in [\"condition\", \"fuel\", \"transmission\", \"drive\", \"type\", \"paint_color\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"unknown\").str.lower()\n",
    "\n",
    "# Filter unrealistic prices and drop missing key fields\n",
    "df = df.dropna(subset=[\"price\", \"year\", \"odometer\"])\n",
    "df = df[(df[\"price\"] > 500) & (df[\"price\"] < 100000)]\n",
    "print(f\"Data shape after cleaning: {df.shape}\")\n",
    "\n",
    "# Reduce high-cardinality columns\n",
    "for col in [\"region\", \"manufacturer\", \"model\"]:\n",
    "    if col in df.columns:\n",
    "        top_cats = df[col].value_counts().nlargest(20).index\n",
    "        df[col] = df[col].apply(lambda x: x if x in top_cats else \"other\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3.1: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# -----------------------------------------------------------------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Price distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df[\"price\"], bins=50, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Distribution of Used Car Prices\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Distribution of Used Car Prices.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Price by condition\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(x=\"condition\", y=\"price\", data=df)\n",
    "plt.title(\"Price by Vehicle Condition\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price by Vehicle Condition.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Price by fuel type\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(x=\"fuel\", y=\"price\", data=df)\n",
    "plt.title(\"Price by Fuel Type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price by Fuel Type.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Price vs year\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(x=\"year\", y=\"price\", data=df, alpha=0.5)\n",
    "plt.title(\"Price vs Model Year\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price vs Model Year.png\")\n",
    "plt.close()\n",
    "\n",
    "# --- Feature selection ---\n",
    "target = \"price\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "num_cols = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Preprocessing pipelines ---\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression — R²: 0.470, RMSE: 10381.69, Duration: 5.28s\n",
      "\n",
      "Ridge Regression best params: {'model__alpha': 10}\n",
      "Ridge Regression — R²: 0.470, RMSE: 10381.53, Duration: 18.59s\n",
      "\n",
      "Lasso Regression best params: {'model__alpha': 0.1}\n",
      "Lasso Regression — R²: 0.465, RMSE: 10431.12, Duration: 20.64s\n",
      "Logistic Regression — Accuracy: 0.863, Precision: 0.867, Recall: 0.856, F1: 0.861, ROC-AUC: 0.931\n"
     ]
    }
   ],
   "source": [
    "# --- Model Training Helper ---\n",
    "results, model_timings = {}, {}\n",
    "\n",
    "def fit_and_eval(name, estimator, param_grid=None, subsample=None):\n",
    "    \"\"\"Fit model, time it, and store metrics.\"\"\"\n",
    "    start = time.time()\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", estimator)])\n",
    "    \n",
    "    if param_grid:\n",
    "        X_sub = X_train.sample(subsample, random_state=42) if subsample else X_train\n",
    "        y_sub = y_train.loc[X_sub.index] if subsample else y_train\n",
    "        grid = GridSearchCV(pipe, param_grid, cv=2, n_jobs=2, scoring=\"r2\")\n",
    "        grid.fit(X_sub, y_sub)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(f\"\\n{name} best params: {grid.best_params_}\")\n",
    "    else:\n",
    "        best_model = pipe.fit(X_train, y_train)\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    r2, rmse = r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"type\": \"regression\", \"R2\": r2, \"RMSE\": rmse, \"Duration\": duration}\n",
    "    model_timings[name] = duration\n",
    "    print(f\"{name} — R²: {r2:.3f}, RMSE: {rmse:.2f}, Duration: {duration:.2f}s\")\n",
    "    # Optional: coefficient interpretation\n",
    "    if hasattr(best_model.named_steps['model'], 'coef_'):\n",
    "        coefs = best_model.named_steps['model'].coef_\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(coefs, bins=30, kde=True)\n",
    "        plt.title(f\"Coefficient Distribution for {name}\")\n",
    "        #plt.show()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"images/Coefficient Distribution for {name}.png\")\n",
    "        plt.close()\n",
    "    return best_model\n",
    "\n",
    "# --- Train models ---\n",
    "lin_model   = fit_and_eval(\"Linear Regression\", LinearRegression())\n",
    "ridge_model = fit_and_eval(\"Ridge Regression\", Ridge(max_iter=5000), {\"model__alpha\":[0.1,1,10]})\n",
    "lasso_model = fit_and_eval(\"Lasso Regression\", Lasso(), {\"model__alpha\":[0.001,0.01,0.1]}, subsample=20000)\n",
    "\n",
    "# =============================================================================\n",
    "# LOGISTIC REGRESSION (Classification)\n",
    "# -----------------------------------------------------------------------------\n",
    "start = time.time()\n",
    "median_price = df[\"price\"].median()\n",
    "df[\"high_price\"] = (df[\"price\"] > median_price).astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"price\", \"high_price\"])\n",
    "y = df[\"high_price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_feats = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "cat_feats = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "preprocessor_log = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_feats),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_feats)\n",
    "])\n",
    "\n",
    "log_reg = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "pipe_log = Pipeline([(\"preprocessor\", preprocessor_log), (\"model\", log_reg)])\n",
    "pipe_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_log.predict(X_test)\n",
    "y_prob = pipe_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "duration = time.time() - start\n",
    "results[\"Logistic Regression\"] = {\n",
    "    \"type\":\"classification\",\n",
    "    \"Accuracy\":acc,\"Precision\":prec,\"Recall\":rec,\n",
    "    \"F1\":f1,\"ROC-AUC\":roc_auc,\"Duration\":duration\n",
    "}\n",
    "model_timings[\"Logistic Regression\"] = duration\n",
    "\n",
    "print(f\"Logistic Regression — Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}, ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# ROC Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\", color=\"teal\")\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/ROC_LogisticRegression.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARIMA(1,0,1) RMSE: 12788.34, Duration: 0.65s\n",
      "\n",
      "=== MODEL EVALUATION SUMMARY ===\n",
      "Linear Regression: R²=0.470, RMSE=10381.69\n",
      "Ridge Regression: R²=0.470, RMSE=10381.53\n",
      "Lasso Regression: R²=0.465, RMSE=10431.12\n",
      "Logistic Regression: Accuracy=0.863, Precision=0.867, Recall=0.856, F1=0.861, ROC-AUC=0.931\n",
      "ARIMA: RMSE=12788.34\n",
      "\n",
      "Best Performing Model: Logistic Regression\n",
      "\n",
      "=== MODEL TRAINING DURATION SUMMARY ===\n",
      "Linear Regression   : 0.09 min (5.3 sec)\n",
      "Ridge Regression    : 0.31 min (18.6 sec)\n",
      "Lasso Regression    : 0.34 min (20.6 sec)\n",
      "Logistic Regression : 0.16 min (9.8 sec)\n",
      "ARIMA               : 0.01 min (0.7 sec)\n",
      "\n",
      "=== TOTAL SCRIPT RUNTIME: 2.96 min (177.4 sec) ===\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 5: EVALUATION (ARIMA Forecast + Model Comparison)\n",
    "# -----------------------------------------------------------------------------\n",
    "start_time = time.time()\n",
    "try:\n",
    "    df_year = df.copy()\n",
    "    df_year[\"year\"] = pd.to_numeric(df_year[\"year\"], errors=\"coerce\")\n",
    "    df_year = df_year.dropna(subset=[\"year\"])\n",
    "    df_year = df_year[df_year[\"year\"] > 1900]\n",
    "    df_year[\"year\"] = df_year[\"year\"].astype(int)\n",
    "\n",
    "    price_by_year = df_year.groupby(\"year\")[\"price\"].mean().sort_index()\n",
    "    \n",
    "    if price_by_year.shape[0] < 5:\n",
    "        raise ValueError(\"Insufficient yearly data for ARIMA.\")\n",
    "\n",
    "    model = ARIMA(price_by_year, order=(1,0,1))\n",
    "    fitted = model.fit()\n",
    "    forecast_steps = 3\n",
    "    forecast_result = fitted.get_forecast(steps=forecast_steps)\n",
    "    forecast = forecast_result.predicted_mean\n",
    "    conf_int = forecast_result.conf_int()\n",
    "\n",
    "    actual_tail = price_by_year.tail(forecast_steps).values\n",
    "    forecast_trimmed = forecast[:len(actual_tail)]\n",
    "    rmse_arima = np.sqrt(mean_squared_error(actual_tail, forecast_trimmed))\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    model_timings[\"ARIMA\"] = duration\n",
    "    results[\"ARIMA\"] = {\"type\": \"regression\", \"R2\": np.nan, \"RMSE\": rmse_arima, \"Duration\": duration}\n",
    "\n",
    "    print(f\"\\nARIMA(1,0,1) RMSE: {rmse_arima:.2f}, Duration: {duration:.2f}s\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.lineplot(x=price_by_year.index, y=price_by_year.values, marker='o', label='Historical Avg Price')\n",
    "    future_years = np.arange(price_by_year.index.max()+1, price_by_year.index.max()+1+forecast_steps)\n",
    "    sns.lineplot(x=future_years, y=forecast, marker='x', label='Forecast', color='darkred')\n",
    "    plt.fill_between(future_years, conf_int.iloc[:,0], conf_int.iloc[:,1], alpha=0.3, label=\"95% CI\",color='lightgray',)\n",
    "    plt.title(\"Average Used Car Price Trend & ARIMA Forecast\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/Average Used Car Price Trend & ARIMA Forecast.png\")\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    duration = time.time() - start_time\n",
    "    model_timings[\"ARIMA\"] = duration\n",
    "    print(f\"ARIMA model failed: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Model evaluation summary ---\n",
    "print(\"\\n=== MODEL EVALUATION SUMMARY ===\")\n",
    "for k,v in results.items():\n",
    "    if v[\"type\"]==\"regression\" and not np.isnan(v.get(\"R2\",np.nan)):\n",
    "        print(f\"{k}: R²={v['R2']:.3f}, RMSE={v['RMSE']:.2f}\")\n",
    "    elif v[\"type\"]==\"classification\":\n",
    "        print(f\"{k}: Accuracy={v['Accuracy']:.3f}, Precision={v['Precision']:.3f}, Recall={v['Recall']:.3f}, F1={v['F1']:.3f}, ROC-AUC={v['ROC-AUC']:.3f}\")\n",
    "    else:\n",
    "        print(f\"{k}: RMSE={v['RMSE']:.2f}\")\n",
    "\n",
    "# Determine best model dynamically\n",
    "reg_models = {k:v for k,v in results.items() if v[\"type\"]==\"regression\"}\n",
    "cls_models = {k:v for k,v in results.items() if v[\"type\"]==\"classification\"}\n",
    "best_reg = max(reg_models.items(), key=lambda x: x[1].get(\"R2\",-np.inf)) if reg_models else None\n",
    "best_cls = max(cls_models.items(), key=lambda x: x[1][\"ROC-AUC\"]) if cls_models else None\n",
    "best_model_name, best_metrics = (best_cls if best_cls else best_reg)\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model_name}\")\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING DURATION SUMMARY ===\")\n",
    "for k,v in model_timings.items():\n",
    "    print(f\"{k:<20}: {v/60:.2f} min ({v:.1f} sec)\")\n",
    "total_time = time.time() - global_start\n",
    "print(f\"\\n=== TOTAL SCRIPT RUNTIME: {total_time/60:.2f} min ({total_time:.1f} sec) ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BUSINESS INSIGHTS & RECOMMENDATIONS ===\n",
      "Best Model: Logistic Regression — Accuracy=0.863, ROC-AUC=0.931\n",
      "\n",
      "• The classification model effectively identifies high-value vehicles.\n",
      "• Use predicted probability (ROC-AUC) to segment vehicles for premium listings.\n",
      "• Focus on features driving higher resale probability (year, odometer, condition).\n",
      "\n",
      "\n",
      "=== RATIONALE: BEST MODEL SELECTION ===\n",
      "\n",
      "Although regression models predict exact price values (R² ~0.47), Logistic Regression classifies vehicles \n",
      "as high vs low price and achieves very high accuracy (86%) and ROC-AUC (0.93). \n",
      "In practical business applications, identifying premium vehicles reliably is more actionable than small \n",
      "differences in continuous price prediction. Therefore, Logistic Regression is selected as the best model \n",
      "for high-value vehicle identification, segmenting inventory, and pricing decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 6: DEPLOYMENT (Business Insights & Model Justification)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== BUSINESS INSIGHTS & RECOMMENDATIONS ===\")\n",
    "if best_metrics[\"type\"] == \"regression\":\n",
    "    print(f\"Best Model: {best_model_name} — R²={best_metrics['R2']:.3f}, RMSE={best_metrics['RMSE']:.2f}\")\n",
    "    print(\"\"\"\n",
    "• Newer model years and lower odometer readings strongly increase resale value.\n",
    "• Good vehicle condition and reputable manufacturers increase price.\n",
    "• High mileage and poor condition decrease value.\n",
    "• Ridge/Lasso provide robust continuous price predictions.\n",
    "• Dealership should prioritize newer, low-mileage, clean vehicles.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"Best Model: {best_model_name} — Accuracy={best_metrics['Accuracy']:.3f}, ROC-AUC={best_metrics['ROC-AUC']:.3f}\")\n",
    "    print(\"\"\"\n",
    "• The classification model effectively identifies high-value vehicles.\n",
    "• Use predicted probability (ROC-AUC) to segment vehicles for premium listings.\n",
    "• Focus on features driving higher resale probability (year, odometer, condition).\n",
    "\"\"\")\n",
    "# === RATIONALE: Why Logistic Regression is Best ===\n",
    "print(\"\\n=== RATIONALE: BEST MODEL SELECTION ===\")\n",
    "print(\"\"\"\n",
    "Although regression models predict exact price values (R² ~0.47), Logistic Regression classifies vehicles \n",
    "as high vs low price and achieves very high accuracy (86%) and ROC-AUC (0.93). \n",
    "In practical business applications, identifying premium vehicles reliably is more actionable than small \n",
    "differences in continuous price prediction. Therefore, Logistic Regression is selected as the best model \n",
    "for high-value vehicle identification, segmenting inventory, and pricing decisions.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Providing complete code base for reference \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_base = \"\"\"\n",
    "### Providing complete code base for reference \n",
    "\"\"\"\n",
    "display(Markdown(code_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRISP-DM FRAMEWORK IMPLEMENTATION\n",
    "# USED CAR PRICE MODELING — REGRESSION, CLASSIFICATION & FORECASTING\n",
    "# =============================================================================\n",
    "\n",
    "# PHASE 0: LIBRARY IMPORTS & INITIALIZATION\n",
    "# -----------------------------------------------------------------------------\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_squared_error,\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create folder for saving images\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Start total timer\n",
    "global_start = time.time()\n",
    "print(\"\\n=== Script started ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 1: BUSINESS UNDERSTANDING\n",
    "# -----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Goal:\n",
    "------\n",
    "To help a used car dealership understand what factors influence used car prices\n",
    "and predict price levels or identify high-value vehicles.\n",
    "\n",
    "Business Objectives:\n",
    "--------------------\n",
    "1. Predict used car resale prices using regression models.\n",
    "2. Classify vehicles as \"high-value\" or \"low-value\" for better inventory targeting.\n",
    "3. Forecast future average price trends for business strategy and acquisition planning.\n",
    "4. Generate actionable insights to guide pricing, procurement, and marketing decisions.\n",
    "\"\"\"\n",
    "# =============================================================================\n",
    "# PHASE 2: DATA UNDERSTANDING\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(\"data/vehicles.csv\")\n",
    "print(f\"Initial dataset shape: {df.shape}\")\n",
    "\n",
    "# Inspect structure and missingness\n",
    "print(\"\\nSample columns:\", df.columns.tolist()[:10])\n",
    "print(df.isna().mean().sort_values(ascending=False).head(10))\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3: DATA PREPARATION\n",
    "# -----------------------------------------------------------------------------\n",
    "# Drop irrelevant columns\n",
    "df.drop(columns=[\"id\", \"VIN\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Fill missing categorical values\n",
    "for col in [\"condition\", \"fuel\", \"transmission\", \"drive\", \"type\", \"paint_color\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"unknown\").str.lower()\n",
    "\n",
    "# Filter unrealistic prices and drop missing key fields\n",
    "df = df.dropna(subset=[\"price\", \"year\", \"odometer\"])\n",
    "df = df[(df[\"price\"] > 500) & (df[\"price\"] < 100000)]\n",
    "print(f\"Data shape after cleaning: {df.shape}\")\n",
    "\n",
    "# Reduce high-cardinality columns\n",
    "for col in [\"region\", \"manufacturer\", \"model\"]:\n",
    "    if col in df.columns:\n",
    "        top_cats = df[col].value_counts().nlargest(20).index\n",
    "        df[col] = df[col].apply(lambda x: x if x in top_cats else \"other\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 3.1: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# -----------------------------------------------------------------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Price distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df[\"price\"], bins=50, kde=True, color=\"skyblue\")\n",
    "plt.title(\"Distribution of Used Car Prices\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Distribution of Used Car Prices.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Price by condition\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(x=\"condition\", y=\"price\", data=df)\n",
    "plt.title(\"Price by Vehicle Condition\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price by Vehicle Condition.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Price by fuel type\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(x=\"fuel\", y=\"price\", data=df)\n",
    "plt.title(\"Price by Fuel Type\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price by Fuel Type.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Price vs year\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.scatterplot(x=\"year\", y=\"price\", data=df, alpha=0.5)\n",
    "plt.title(\"Price vs Model Year\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/Price vs Model Year.png\")\n",
    "plt.close()\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 4: MODELING\n",
    "# -----------------------------------------------------------------------------\n",
    "# --- Feature selection ---\n",
    "target = \"price\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "num_cols = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Preprocessing pipelines ---\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# --- Model Training Helper ---\n",
    "results, model_timings = {}, {}\n",
    "\n",
    "def fit_and_eval(name, estimator, param_grid=None, subsample=None):\n",
    "    \"\"\"Fit model, time it, and store metrics.\"\"\"\n",
    "    start = time.time()\n",
    "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"model\", estimator)])\n",
    "    \n",
    "    if param_grid:\n",
    "        X_sub = X_train.sample(subsample, random_state=42) if subsample else X_train\n",
    "        y_sub = y_train.loc[X_sub.index] if subsample else y_train\n",
    "        grid = GridSearchCV(pipe, param_grid, cv=2, n_jobs=2, scoring=\"r2\")\n",
    "        grid.fit(X_sub, y_sub)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(f\"\\n{name} best params: {grid.best_params_}\")\n",
    "    else:\n",
    "        best_model = pipe.fit(X_train, y_train)\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    r2, rmse = r2_score(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {\"type\": \"regression\", \"R2\": r2, \"RMSE\": rmse, \"Duration\": duration}\n",
    "    model_timings[name] = duration\n",
    "    print(f\"{name} — R²: {r2:.3f}, RMSE: {rmse:.2f}, Duration: {duration:.2f}s\")\n",
    "    # Optional: coefficient interpretation\n",
    "    if hasattr(best_model.named_steps['model'], 'coef_'):\n",
    "        coefs = best_model.named_steps['model'].coef_\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(coefs, bins=30, kde=True)\n",
    "        plt.title(f\"Coefficient Distribution for {name}\")\n",
    "        #plt.show()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"images/Coefficient Distribution for {name}.png\")\n",
    "        plt.close()\n",
    "    return best_model\n",
    "\n",
    "# --- Train models ---\n",
    "lin_model   = fit_and_eval(\"Linear Regression\", LinearRegression())\n",
    "ridge_model = fit_and_eval(\"Ridge Regression\", Ridge(max_iter=5000), {\"model__alpha\":[0.1,1,10]})\n",
    "lasso_model = fit_and_eval(\"Lasso Regression\", Lasso(), {\"model__alpha\":[0.001,0.01,0.1]}, subsample=20000)\n",
    "\n",
    "# =============================================================================\n",
    "# LOGISTIC REGRESSION (Classification)\n",
    "# -----------------------------------------------------------------------------\n",
    "start = time.time()\n",
    "median_price = df[\"price\"].median()\n",
    "df[\"high_price\"] = (df[\"price\"] > median_price).astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"price\", \"high_price\"])\n",
    "y = df[\"high_price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_feats = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "cat_feats = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "preprocessor_log = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_feats),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_feats)\n",
    "])\n",
    "\n",
    "log_reg = LogisticRegression(penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "pipe_log = Pipeline([(\"preprocessor\", preprocessor_log), (\"model\", log_reg)])\n",
    "pipe_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_log.predict(X_test)\n",
    "y_prob = pipe_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "duration = time.time() - start\n",
    "results[\"Logistic Regression\"] = {\n",
    "    \"type\":\"classification\",\n",
    "    \"Accuracy\":acc,\"Precision\":prec,\"Recall\":rec,\n",
    "    \"F1\":f1,\"ROC-AUC\":roc_auc,\"Duration\":duration\n",
    "}\n",
    "model_timings[\"Logistic Regression\"] = duration\n",
    "\n",
    "print(f\"Logistic Regression — Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}, ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "# ROC Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.2f}\", color=\"teal\")\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.title(\"ROC Curve — Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/ROC_LogisticRegression.png\")\n",
    "plt.close()\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 5: EVALUATION (ARIMA Forecast + Model Comparison)\n",
    "# -----------------------------------------------------------------------------\n",
    "start_time = time.time()\n",
    "try:\n",
    "    df_year = df.copy()\n",
    "    df_year[\"year\"] = pd.to_numeric(df_year[\"year\"], errors=\"coerce\")\n",
    "    df_year = df_year.dropna(subset=[\"year\"])\n",
    "    df_year = df_year[df_year[\"year\"] > 1900]\n",
    "    df_year[\"year\"] = df_year[\"year\"].astype(int)\n",
    "\n",
    "    price_by_year = df_year.groupby(\"year\")[\"price\"].mean().sort_index()\n",
    "    \n",
    "    if price_by_year.shape[0] < 5:\n",
    "        raise ValueError(\"Insufficient yearly data for ARIMA.\")\n",
    "\n",
    "    model = ARIMA(price_by_year, order=(1,0,1))\n",
    "    fitted = model.fit()\n",
    "    forecast_steps = 3\n",
    "    forecast_result = fitted.get_forecast(steps=forecast_steps)\n",
    "    forecast = forecast_result.predicted_mean\n",
    "    conf_int = forecast_result.conf_int()\n",
    "\n",
    "    actual_tail = price_by_year.tail(forecast_steps).values\n",
    "    forecast_trimmed = forecast[:len(actual_tail)]\n",
    "    rmse_arima = np.sqrt(mean_squared_error(actual_tail, forecast_trimmed))\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    model_timings[\"ARIMA\"] = duration\n",
    "    results[\"ARIMA\"] = {\"type\": \"regression\", \"R2\": np.nan, \"RMSE\": rmse_arima, \"Duration\": duration}\n",
    "\n",
    "    print(f\"\\nARIMA(1,0,1) RMSE: {rmse_arima:.2f}, Duration: {duration:.2f}s\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.lineplot(x=price_by_year.index, y=price_by_year.values, marker='o', label='Historical Avg Price')\n",
    "    future_years = np.arange(price_by_year.index.max()+1, price_by_year.index.max()+1+forecast_steps)\n",
    "    sns.lineplot(x=future_years, y=forecast, marker='x', label='Forecast', color='darkred')\n",
    "    plt.fill_between(future_years, conf_int.iloc[:,0], conf_int.iloc[:,1], alpha=0.3, label=\"95% CI\",color='lightgray',)\n",
    "    plt.title(\"Average Used Car Price Trend & ARIMA Forecast\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/Average Used Car Price Trend & ARIMA Forecast.png\")\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    duration = time.time() - start_time\n",
    "    model_timings[\"ARIMA\"] = duration\n",
    "    print(f\"ARIMA model failed: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Model evaluation summary ---\n",
    "print(\"\\n=== MODEL EVALUATION SUMMARY ===\")\n",
    "for k,v in results.items():\n",
    "    if v[\"type\"]==\"regression\" and not np.isnan(v.get(\"R2\",np.nan)):\n",
    "        print(f\"{k}: R²={v['R2']:.3f}, RMSE={v['RMSE']:.2f}\")\n",
    "    elif v[\"type\"]==\"classification\":\n",
    "        print(f\"{k}: Accuracy={v['Accuracy']:.3f}, Precision={v['Precision']:.3f}, Recall={v['Recall']:.3f}, F1={v['F1']:.3f}, ROC-AUC={v['ROC-AUC']:.3f}\")\n",
    "    else:\n",
    "        print(f\"{k}: RMSE={v['RMSE']:.2f}\")\n",
    "\n",
    "# Determine best model dynamically\n",
    "reg_models = {k:v for k,v in results.items() if v[\"type\"]==\"regression\"}\n",
    "cls_models = {k:v for k,v in results.items() if v[\"type\"]==\"classification\"}\n",
    "best_reg = max(reg_models.items(), key=lambda x: x[1].get(\"R2\",-np.inf)) if reg_models else None\n",
    "best_cls = max(cls_models.items(), key=lambda x: x[1][\"ROC-AUC\"]) if cls_models else None\n",
    "best_model_name, best_metrics = (best_cls if best_cls else best_reg)\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model_name}\")\n",
    "\n",
    "print(\"\\n=== MODEL TRAINING DURATION SUMMARY ===\")\n",
    "for k,v in model_timings.items():\n",
    "    print(f\"{k:<20}: {v/60:.2f} min ({v:.1f} sec)\")\n",
    "total_time = time.time() - global_start\n",
    "print(f\"\\n=== TOTAL SCRIPT RUNTIME: {total_time/60:.2f} min ({total_time:.1f} sec) ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# PHASE 6: DEPLOYMENT (Business Insights & Model Justification)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== BUSINESS INSIGHTS & RECOMMENDATIONS ===\")\n",
    "if best_metrics[\"type\"] == \"regression\":\n",
    "    print(f\"Best Model: {best_model_name} — R²={best_metrics['R2']:.3f}, RMSE={best_metrics['RMSE']:.2f}\")\n",
    "    print(\"\"\"\n",
    "• Newer model years and lower odometer readings strongly increase resale value.\n",
    "• Good vehicle condition and reputable manufacturers increase price.\n",
    "• High mileage and poor condition decrease value.\n",
    "• Ridge/Lasso provide robust continuous price predictions.\n",
    "• Dealership should prioritize newer, low-mileage, clean vehicles.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"Best Model: {best_model_name} — Accuracy={best_metrics['Accuracy']:.3f}, ROC-AUC={best_metrics['ROC-AUC']:.3f}\")\n",
    "    print(\"\"\"\n",
    "• The classification model effectively identifies high-value vehicles.\n",
    "• Use predicted probability (ROC-AUC) to segment vehicles for premium listings.\n",
    "• Focus on features driving higher resale probability (year, odometer, condition).\n",
    "\"\"\")\n",
    "# === RATIONALE: Why Logistic Regression is Best ===\n",
    "print(\"\\n=== RATIONALE: BEST MODEL SELECTION ===\")\n",
    "print(\"\"\"\n",
    "Although regression models predict exact price values (R² ~0.47), Logistic Regression classifies vehicles \n",
    "as high vs low price and achieves very high accuracy (86%) and ROC-AUC (0.93). \n",
    "In practical business applications, identifying premium vehicles reliably is more actionable than small \n",
    "differences in continuous price prediction. Therefore, Logistic Regression is selected as the best model \n",
    "for high-value vehicle identification, segmenting inventory, and pricing decisions.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
